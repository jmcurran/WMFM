% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llmHelpers.R
\name{lmEquations}
\alias{lmEquations}
\title{Get fitted-model equations via the language model (with caching)}
\usage{
lmEquations(model, chat)
}
\arguments{
\item{model}{A fitted model object, typically of class \code{"lm"} or
\code{"glm"}.}

\item{chat}{A chat provider object as returned by \code{getChatProvider()}.}
}
\value{
Either a tibble with columns \code{condition} and \code{equation},
or a character vector with raw text from the language model.
}
\description{
Calls the chat provider with a prompt constructed from a fitted model and
returns the fitted-model equations. Results are cached based on the model
formula and coefficients to avoid repeated calls for the same model.
}
\details{
If the provider supports structured output (e.g. OpenAI via ellmer),
the result is converted to a tibble with \code{condition} and
\code{equation} columns. Otherwise, a character vector is returned.
}
\keyword{internal}
